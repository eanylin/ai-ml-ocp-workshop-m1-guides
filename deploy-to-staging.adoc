## Deploy The Model To Staging

The model has been tested in the development environment and is now ready to be deployed to the staging environment.

Once we code is pushed to the git repository, the pipeline will run to build and train the image. We will also be using Argo CD as the GitOps tool to deploy the model to the staging environment.

To get started, {{ECLIPSE_CHE_URL}}[access the
CodeReady Workspaces instance^], and log in using the username and
password you have been assigned
(e.g. `{{ USER_ID }}/{{ CHE_USER_PASSWORD }}`):

## OpenShift Pipelines

OpenShift Pipelines is a Kubernetes-style CI/CD solution based on Tekton. It builds on the Tekton building blocks and provides a CI/CD experience through tight integration with OpenShift and Red Hat developer tools. 

A Tekton {{CONSOLE_URL}}/k8s/ns/{{USER_ID}}-stage/tekton.dev\~v1alpha1~Pipeline[pipeline^]
has been created for you.

[NOTE]
====
Here, users are able to explore the different stages of the pipeline  
====

image:pipeline.png[pipeline]

The pipeline consists of the following stages

* Git clone the source code
* Run `train-stage.sh` to train the model
* Build the image using S2I (Source-to-Image)
* Push the image into Nexus registry

## Argo CD

Argo CD is a declarative continuous delivery tool that leverages GitOps to maintain cluster resources. Argo CD is implemented as a controller that continuously monitors application definitions and configurations defined in a Git repository and compares the specified state of those configurations with their live state on the cluster. Configurations that deviate from their specified state in the Git repository are classified as OutOfSync. Argo CD reports these differences and allows administrators to automatically or manually resync configurations to the defined state.

## Training script

`train-stage.sh` has been written to be used in the pipeline to call your python script and saves the model into the pipeline workspace. `train-stage.sh` can be found in your {{GIT_URL}}/{{USER_ID}}/{{USER_MODEL_REPO_NAME}}/[Gogs^] repository. The training script uses a `config.sh` that allows you to define the model to be trained.

Under /projects/{{USER_MODEL_REPO_NAME}}/workshop/src/train/config.sh:

[NOTE]
====
Note that the code directly below this statement is not meant to be run but serves as an illustration for the user to take note that the python script used is lr.py and the associated run name is lr.
====

[source,sh,role="copypaste"]
----
PYTHON_SCRIPT=lr.py
RUN_NAME=lr
----

## Building The Image

Once the model has been saved into the pipeline workspace, the building stage will begin to assemble the image by calling `S2I` and `buildah`.

https://developers.redhat.com/blog/2019/02/21/podman-and-buildah-for-docker-users/[Buildah^] is a tool that facilitates building Open Container Initiative (OCI) container images.

image::buildah.png[buildah, 700]

S2I follows a well https://docs.openshift.com/container-platform/4.4/builds/build-strategies.html#images-create-s2i-build_build-strategie[defined^] repository https://github.com/sclorg/s2i-python-container/tree/master/3.6[layout^], which includes the following files:

* `requirements.txt`, for python dependencies
* `.s2i/bin/assemble`, to customize image assembling 
* `.s2i/environment`, custom environment variables
* `app.py`, python script to launch the application

In our workshop, we have overridden the `APP_SCRIPT` environment variable to use `app.sh` to launch the model.

The source code is available {{GIT_URL}}/{{USER_ID}}/{{USER_MODEL_REPO_NAME}}/src/master/src/seldon[here^] 

## Deployment

Once the image has been pushed to Nexus, we will deploy the model using Seldon's operator by creating a `SeldonDeployment` resource.

Seldon Core, an open-source framework, makes it easier and faster to deploy your machine learning models and experiments at scale on Kubernetes. Seldon Core extends Kubernetes with its own custom resource `SeldonDeployment` where you can define your runtime inference graph made up of models and other components that Seldon will manage.

A `SeldonDeployment` is a JSON or YAML file that allows you to define your graph of component images and the resources each of those images will need to run (using a Kubernetes PodTemplateSpec). The parts of a SeldonDeployment are shown below:

image::seldon-inf-graph.png[seldon-inf-graph]

## Push To Staging Branch

Now let's push the code to the staging branch so that the pipeline will run.

[source,sh,role="copypaste"]
----
git checkout -b stage
git push -u -v origin stage
----

image::gogs-staging-branch.png[gogs-staging-branch, 300]

Because Gogs has been configured with a {{GIT_URL}}/{{USER_ID}}/{{USER_MODEL_REPO_NAME}}/settings/hooks[webhook^], a git push will trigger our pipeline.

[WARNING]
====
Do not change the webhook.
====

You can go to OpenShift Console to monitor the {{CONSOLE_URL}}/k8s/ns/{{USER_ID}}-stage/tekton.dev\~v1alpha1~PipelineRun[pipeline run^]. If you are accessing the Pipeline Run from the {{CONSOLE_URL}}[OpenShift Console^], under the {{USER_ID}}-stage project namespace: You can select `Pipelines` (from the left panel) -> `Pipeline Runs`. 

[NOTE]
====
The pipeline run is estimated to take about 10 minutes.
====

If any error occurs during the pipeline run, we can stop the pipeline run from the OpenShift UI as shown below.
 
image::pipeline-openshift-ui.png[pipeline-openshift-ui]
 
To trigger a new pipeline run, we can do an empty git commit.
 
[source,sh,role="copypaste"]
----
git checkout stage
git commit --allow-empty -m "Empty commit to trigger pipeline run again"
git push -u -v origin stage
----
This will trigger a new pipeline run which can be viewed in the OpenShift UI.

Once the pipeline runs finish, the image would have been pushed into {{NEXUS_URL}}/#browse/browse:docker-registry[Nexus Registry^] and is tagged with the git revision number. This allows us to provide model provenance by tracking the source code, data version used and the image being used. As depicted, the created image is tagged and is under user/lr/tags.

image::docker-registry.png[docker-registry]

## Deploy to Staging

Argo CD follows the GitOps model of deployment, where desired configuration changes are first pushed to Git, and the cluster state then syncs to the desired state in git. 

We will now modify the `SeldonDeployment` to deploy our new image that is tagged with the git revision.

[WARNING]
====
Please ensure that the Pipeline above runs finish before proceeding to the next stage.
====

[source,sh,role="copypaste"]
----
cd /projects/{{USER_MODEL_REPO_NAME}}
git checkout stage
GIT_REV=`git rev-parse --short HEAD`
echo "GIT REVISION: $GIT_REV"
. src/seldon/config.sh

cd /projects/{{USER_DEPLOY_REPO_NAME}}
git checkout master
sed -e "s/_USER_/{{USER_ID}}/g" -e "s/_CONTAINER_REGISTRY_/$NEXUS_DOCKER_REGISTRY/g" -e "s/_IMAGE_NAME_/$IMAGE_NAME/g" -e "s/_GIT_REV_/$GIT_REV/g" seldon-model.yaml.tmpl > seldon.yaml
git add *.yaml
git commit -a -m "Update image tag to $IMAGE_NAME:$GIT_REV"

git checkout -b stage
git merge master
git push -u -v origin stage
----

View the `seldon.yaml` in the IDE and notice that image name has been updated with the specific tag. 
[source,yaml]
----
spec:
  containers:
    - image: {{NEXUS_DOCKER_REGISTRY}}/{{USER_ID}}/lr:1234
----

Argo CD is configured to monitor your deployment for the `stage` and `prod` branch in your git 
{{GIT_URL}}/{{USER_ID}}/{{USER_DEPLOY_REPO_NAME}}[repository^]. You can login to {{ARGOCD_URL}}/applications/{{USER_ID}}-stage[Argo CD^] with your `{{USER_ID}}/{{OPENSHIFT_USER_PASSWORD}}` credential.

[NOTE]
====
Here, users are able to log in by clicking on the `Login via OpenShift` button 
====

Once the deployment has been pushed, Argo CD will be triggered via a webhook to push the deployment over to OpenShift. 

image::argocd-deploy.png[argocd-deploy]

A `Deployment` resource will be created. The pods should be running and in a ready state. You can view them under {{CONSOLE_URL}}/k8s/ns/{{USER_ID}}-stage/deployments[OpenShift Console^]. 

image::seldon-deploy.png[seldon-deploy]

You will notice there is a Seldon service orchestrator pod running. The service orchestrator is a component that is added to your inference graph to:

* Correctly manage the request/response paths described by your inference graph
* Expose Prometheus metrics
* Provide Tracing via Open Tracing
* Add CloudEvent based payload logging

image::seldon-svc-orch.png[seldon-svc-orch]

## Model Testing

Once the model has been deployed and is running, you can now run some simple tests. The test will send sample data to the prediction endpoint. 

[source,sh,role="copypaste"]
----
/projects/{{USER_MODEL_REPO_NAME}}/bin/stage-test.sh
----
